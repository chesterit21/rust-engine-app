Ini implementasi lengkapnya:

***

**`src/database/listener.rs`**

```rust
use super::{DbPool, DocumentNotification};
use anyhow::Result;
use futures::StreamExt;
use serde_json;
use tokio::sync::mpsc;
use tokio_postgres::AsyncMessage;
use tracing::{debug, error, info, warn};

pub struct NotificationListener {
    pool: DbPool,
    channel: String,
}

impl NotificationListener {
    pub fn new(pool: DbPool, channel: String) -> Self {
        Self { pool, channel }
    }
    
    /// Start listening untuk PostgreSQL notifications
    /// Returns channel untuk receive notifications
    pub async fn start(
        &self,
    ) -> Result<mpsc::UnboundedReceiver<DocumentNotification>> {
        let (tx, rx) = mpsc::unbounded_channel();
        
        // Create dedicated connection untuk LISTEN
        let (client, mut connection) = tokio_postgres::connect(
            &self.pool.get_pool().connect_options().to_string(),
            tokio_postgres::NoTls,
        )
        .await?;
        
        // Execute LISTEN command
        client
            .execute(&format!("LISTEN {}", self.channel), &[])
            .await?;
        
        info!("âœ… Started listening on channel: {}", self.channel);
        
        // Spawn task untuk handle connection stream
        tokio::spawn(async move {
            loop {
                tokio::select! {
                    // Handle connection messages
                    message = connection.next() => {
                        match message {
                            Some(Ok(AsyncMessage::Notification(notif))) => {
                                debug!("Received notification: {:?}", notif.payload());
                                
                                // Parse JSON payload
                                match serde_json::from_str::<DocumentNotification>(notif.payload()) {
                                    Ok(doc_notif) => {
                                        if let Err(e) = tx.send(doc_notif) {
                                            error!("Failed to send notification to channel: {}", e);
                                            break;
                                        }
                                    }
                                    Err(e) => {
                                        error!("Failed to parse notification payload: {}", e);
                                    }
                                }
                            }
                            Some(Ok(AsyncMessage::Notice(notice))) => {
                                debug!("Received notice: {:?}", notice);
                            }
                            Some(Err(e)) => {
                                error!("Connection error: {}", e);
                                break;
                            }
                            None => {
                                warn!("Connection stream ended");
                                break;
                            }
                            _ => {}
                        }
                    }
                    
                    // Keep-alive check setiap 30 detik
                    _ = tokio::time::sleep(tokio::time::Duration::from_secs(30)) => {
                        if let Err(e) = client.simple_query("SELECT 1").await {
                            error!("Keep-alive check failed: {}", e);
                            break;
                        }
                    }
                }
            }
            
            error!("Listener connection closed");
        });
        
        Ok(rx)
    }
}
```

***

### ðŸ“¡ EMBEDDING LAYER (Llama-server Manager)

**`src/embedding/mod.rs`**

```rust
pub mod provider;
pub mod llama_server;

pub use provider::{EmbeddingProvider, EmbeddingRequest, EmbeddingResponse};
pub use llama_server::LlamaServerManager;
```

**`src/embedding/provider.rs`**

```rust
use anyhow::Result;
use async_trait::async_trait;

#[derive(Debug, Clone)]
pub struct EmbeddingRequest {
    pub texts: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct EmbeddingResponse {
    pub embeddings: Vec<Vec<f32>>,
}

#[async_trait]
pub trait EmbeddingProvider: Send + Sync {
    async fn embed(&self, request: EmbeddingRequest) -> Result<EmbeddingResponse>;
    async fn embed_single(&self, text: String) -> Result<Vec<f32>>;
}
```

**`src/embedding/llama_server.rs`**

```rust
use super::{EmbeddingProvider, EmbeddingRequest, EmbeddingResponse};
use crate::config::LlamaServerConfig;
use anyhow::{anyhow, Result};
use async_trait::async_trait;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::process::{Child, Command, Stdio};
use std::time::Duration;
use sysinfo::{System, SystemExt};
use tokio::time::{sleep, timeout};
use tracing::{debug, error, info, warn};

#[derive(Debug, Serialize)]
struct LlamaEmbeddingRequest {
    content: String,
}

#[derive(Debug, Deserialize)]
struct LlamaEmbeddingResponse {
    embedding: Vec<f32>,
}

pub struct LlamaServerManager {
    config: LlamaServerConfig,
    client: Client,
    process: Option<Child>,
    base_url: String,
}

impl LlamaServerManager {
    pub fn new(config: LlamaServerConfig) -> Self {
        let base_url = format!("http://{}:{}", config.host, config.port);
        
        Self {
            config,
            client: Client::builder()
                .timeout(Duration::from_secs(300))
                .build()
                .expect("Failed to create HTTP client"),
            process: None,
            base_url,
        }
    }
    
    /// Check available system memory
    pub fn check_memory(&self) -> Result<u64> {
        let mut sys = System::new_all();
        sys.refresh_memory();
        
        let available_mb = sys.available_memory() / 1024 / 1024;
        info!("Available memory: {} MB", available_mb);
        
        if available_mb < 2048 {
            anyhow::bail!("Not enough memory to start embedding server (< 2GB available)");
        }
        
        Ok(available_mb)
    }
    
    /// Start llama-server process
    pub async fn start(&mut self) -> Result<()> {
        // Check if already running
        if self.is_running().await {
            info!("Llama-server already running");
            return Ok(());
        }
        
        // Check available memory
        self.check_memory()?;
        
        info!("ðŸš€ Starting llama-server...");
        
        // Build command
        let mut cmd = Command::new(&self.config.binary_path);
        
        cmd.arg("--model")
            .arg(&self.config.model_path)
            .arg("--host")
            .arg(&self.config.host)
            .arg("--port")
            .arg(self.config.port.to_string())
            .arg("--ctx-size")
            .arg(self.config.ctx_size.to_string())
            .arg("--threads")
            .arg(self.config.threads.to_string());
        
        // Embedding-only mode (no generation)
        if self.config.embedding_only {
            cmd.arg("--embedding");
        }
        
        // Suppress verbose output
        cmd.stdout(Stdio::null())
            .stderr(Stdio::piped());
        
        // Spawn process
        let child = cmd.spawn()
            .map_err(|e| anyhow!("Failed to spawn llama-server: {}", e))?;
        
        self.process = Some(child);
        
        info!("Process spawned, waiting for server to be ready...");
        
        // Wait for server to be ready
        let ready = timeout(
            Duration::from_secs(self.config.startup_timeout_seconds),
            self.wait_until_ready(),
        )
        .await;
        
        match ready {
            Ok(Ok(_)) => {
                info!("âœ… Llama-server ready");
                Ok(())
            }
            Ok(Err(e)) => {
                self.stop().await?;
                Err(anyhow!("Server failed to start: {}", e))
            }
            Err(_) => {
                self.stop().await?;
                Err(anyhow!("Server startup timeout"))
            }
        }
    }
    
    /// Check if server is running and responding
    async fn is_running(&self) -> bool {
        match self.client
            .get(&format!("{}/health", self.base_url))
            .send()
            .await
        {
            Ok(response) => response.status().is_success(),
            Err(_) => false,
        }
    }
    
    /// Wait until server is ready
    async fn wait_until_ready(&self) -> Result<()> {
        let mut attempts = 0;
        let max_attempts = 60; // 60 attempts * 1 second = 1 minute
        
        loop {
            if self.is_running().await {
                return Ok(());
            }
            
            attempts += 1;
            if attempts >= max_attempts {
                return Err(anyhow!("Server not responding after {} attempts", max_attempts));
            }
            
            sleep(Duration::from_secs(1)).await;
        }
    }
    
    /// Stop llama-server process
    pub async fn stop(&mut self) -> Result<()> {
        if let Some(mut child) = self.process.take() {
            info!("ðŸ›‘ Stopping llama-server...");
            
            // Try graceful shutdown first
            match child.kill() {
                Ok(_) => {
                    // Wait for process to exit
                    let wait_result = timeout(
                        Duration::from_secs(self.config.shutdown_timeout_seconds),
                        tokio::task::spawn_blocking(move || child.wait()),
                    )
                    .await;
                    
                    match wait_result {
                        Ok(Ok(Ok(status))) => {
                            info!("Llama-server stopped with status: {}", status);
                        }
                        _ => {
                            warn!("Failed to wait for process exit");
                        }
                    }
                }
                Err(e) => {
                    error!("Failed to kill process: {}", e);
                }
            }
        }
        
        Ok(())
    }
    
    /// Embed single text
    async fn embed_text(&self, text: &str) -> Result<Vec<f32>> {
        let request = LlamaEmbeddingRequest {
            content: text.to_string(),
        };
        
        let response = self
            .client
            .post(&format!("{}/embedding", self.base_url))
            .json(&request)
            .send()
            .await?;
        
        if !response.status().is_success() {
            let status = response.status();
            let body = response.text().await.unwrap_or_default();
            anyhow::bail!("Embedding request failed: {} - {}", status, body);
        }
        
        let llama_response: LlamaEmbeddingResponse = response.json().await?;
        
        Ok(llama_response.embedding)
    }
}

#[async_trait]
impl EmbeddingProvider for LlamaServerManager {
    async fn embed(&self, request: EmbeddingRequest) -> Result<EmbeddingResponse> {
        let mut embeddings = Vec::with_capacity(request.texts.len());
        
        for (i, text) in request.texts.iter().enumerate() {
            debug!("Embedding text {}/{}", i + 1, request.texts.len());
            
            let embedding = self.embed_text(text).await?;
            embeddings.push(embedding);
        }
        
        Ok(EmbeddingResponse { embeddings })
    }
    
    async fn embed_single(&self, text: String) -> Result<Vec<f32>> {
        self.embed_text(&text).await
    }
}

impl Drop for LlamaServerManager {
    fn drop(&mut self) {
        // Cleanup on drop
        if let Some(mut child) = self.process.take() {
            let _ = child.kill();
        }
    }
}
```

**ðŸ“Œ Referensi:** [Llama.cpp server API](https://github.com/ggml-org/llama.cpp), [Process spawning in Rust](https://kobzol.github.io/rust/2024/01/28/process-spawning-performance-in-rust.html) [github](https://github.com/ggml-org/llama.cpp)

***

### ðŸ“„ DOCUMENT PROCESSING LAYER

**`src/document/mod.rs`**

```rust
pub mod loader;
pub mod parser;
pub mod chunker;

pub use loader::DocumentLoader;
pub use parser::{DocumentParser, ParsedDocument};
pub use chunker::{TextChunker, Chunk};
```

**`src/document/loader.rs`**

```rust
use anyhow::{anyhow, Result};
use mime_guess;
use std::fs;
use std::path::{Path, PathBuf};
use tracing::{debug, warn};

pub struct DocumentLoader;

impl DocumentLoader {
    /// Load file content from path
    pub fn load_file(path: &Path) -> Result<Vec<u8>> {
        if !path.exists() {
            anyhow::bail!("File not found: {:?}", path);
        }
        
        if !path.is_file() {
            anyhow::bail!("Path is not a file: {:?}", path);
        }
        
        let content = fs::read(path)?;
        debug!("Loaded file: {:?} ({} bytes)", path, content.len());
        
        Ok(content)
    }
    
    /// Detect file type from path
    pub fn detect_file_type(path: &Path) -> Result<String> {
        let mime = mime_guess::from_path(path).first_or_octet_stream();
        let file_type = mime.essence_str().to_string();
        
        debug!("Detected file type: {} for {:?}", file_type, path);
        
        Ok(file_type)
    }
    
    /// Check if file is supported for text extraction
    pub fn is_supported(path: &Path) -> bool {
        let extension = path
            .extension()
            .and_then(|e| e.to_str())
            .map(|e| e.to_lowercase());
        
        match extension.as_deref() {
            // Documents
            Some("txt") | Some("md") | Some("pdf") | Some("docx") | Some("doc") => true,
            
            // Web
            Some("html") | Some("htm") | Some("xml") => true,
            
            // Code
            Some("rs") | Some("py") | Some("js") | Some("ts") | Some("java") |
            Some("c") | Some("cpp") | Some("cs") | Some("go") | Some("rb") |
            Some("php") | Some("swift") | Some("kt") => true,
            
            // Config/Data
            Some("json") | Some("yaml") | Some("yml") | Some("toml") |
            Some("csv") | Some("sql") => true,
            
            // Other text
            Some("log") | Some("sh") | Some("bash") | Some("css") => true,
            
            _ => {
                // Check MIME type as fallback
                let mime = mime_guess::from_path(path).first();
                match mime {
                    Some(m) if m.type_() == mime::TEXT => true,
                    _ => false,
                }
            }
        }
    }
    
    /// Validate file before processing
    pub fn validate_file(path: &Path, max_size_mb: u64) -> Result<()> {
        if !path.exists() {
            anyhow::bail!("File not found: {:?}", path);
        }
        
        if !Self::is_supported(path) {
            anyhow::bail!("Unsupported file type: {:?}", path);
        }
        
        let metadata = fs::metadata(path)?;
        let size_mb = metadata.len() / 1024 / 1024;
        
        if size_mb > max_size_mb {
            anyhow::bail!(
                "File too large: {} MB (max: {} MB)",
                size_mb,
                max_size_mb
            );
        }
        
        Ok(())
    }
}
```

**`src/document/parser.rs`**

```rust
use anyhow::{anyhow, Result};
use encoding_rs::{Encoding, UTF_8};
use lopdf::Document as PdfDocument;
use pulldown_cmark::{Parser as MdParser, html, Options};
use scraper::{Html, Selector};
use std::fs;
use std::io::{BufRead, BufReader};
use std::path::Path;
use tracing::{debug, warn};

#[derive(Debug, Clone)]
pub struct ParsedDocument {
    pub content: String,
    pub metadata: DocumentMetadata,
}

#[derive(Debug, Clone)]
pub struct DocumentMetadata {
    pub file_type: String,
    pub pages: Option<usize>,
    pub char_count: usize,
    pub encoding: String,
}

pub struct DocumentParser;

impl DocumentParser {
    /// Parse document dari path
    pub fn parse(path: &Path) -> Result<ParsedDocument> {
        let extension = path
            .extension()
            .and_then(|e| e.to_str())
            .ok_or_else(|| anyhow!("No file extension"))?
            .to_lowercase();
        
        debug!("Parsing file: {:?} (type: {})", path, extension);
        
        let (content, metadata) = match extension.as_str() {
            "pdf" => Self::parse_pdf(path)?,
            "docx" => Self::parse_docx(path)?,
            "md" => Self::parse_markdown(path)?,
            "html" | "htm" => Self::parse_html(path)?,
            _ => Self::parse_text(path)?, // fallback untuk semua text-based
        };
        
        debug!("Parsed {} characters from {:?}", content.len(), path);
        
        Ok(ParsedDocument { content, metadata })
    }
    
    /// Parse PDF using lopdf
    fn parse_pdf(path: &Path) -> Result<(String, DocumentMetadata)> {
        let doc = PdfDocument::load(path)?;
        let pages = doc.get_pages();
        let page_count = pages.len();
        
        let mut content = String::new();
        
        for (page_num, _) in pages.iter() {
            match doc.extract_text(&[*page_num]) {
                Ok(text) => {
                    content.push_str(&text);
                    content.push('\n');
                }
                Err(e) => {
                    warn!("Failed to extract text from page {}: {}", page_num, e);
                }
            }
        }
        
        let metadata = DocumentMetadata {
            file_type: "application/pdf".to_string(),
            pages: Some(page_count),
            char_count: content.len(),
            encoding: "UTF-8".to_string(),
        };
        
        Ok((content, metadata))
    }
    
    /// Parse DOCX
    fn parse_docx(path: &Path) -> Result<(String, DocumentMetadata)> {
        let content = fs::read(path)?;
        let doc = docx_rs::read_docx(&content)?;
        
        // Extract text dari document
        let text = doc.document.to_string();
        
        let metadata = DocumentMetadata {
            file_type: "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                .to_string(),
            pages: None,
            char_count: text.len(),
            encoding: "UTF-8".to_string(),
        };
        
        Ok((text, metadata))
    }
    
    /// Parse Markdown dan convert ke plain text
    fn parse_markdown(path: &Path) -> Result<(String, DocumentMetadata)> {
        let raw_content = fs::read(path)?;
        let (content, encoding) = Self::decode_text(&raw_content)?;
        
        // Parse markdown ke HTML dulu, lalu extract text
        let parser = MdParser::new_ext(&content, Options::all());
        let mut html_output = String::new();
        html::push_html(&mut html_output, parser);
        
        // Extract text from HTML
        let text = Self::extract_text_from_html(&html_output)?;
        
        let metadata = DocumentMetadata {
            file_type: "text/markdown".to_string(),
            pages: None,
            char_count: text.len(),
            encoding: encoding.to_string(),
        };
        
        Ok((text, metadata))
    }
    
    /// Parse HTML dan extract text
    fn parse_html(path: &Path) -> Result<(String, DocumentMetadata)> {
        let raw_content = fs::read(path)?;
        let (content, encoding) = Self::decode_text(&raw_content)?;
        
        let text = Self::extract_text_from_html(&content)?;
        
        let metadata = DocumentMetadata {
            file_type: "text/html".to_string(),
            pages: None,
            char_count: text.len(),
            encoding: encoding.to_string(),
        };
        
        Ok((text, metadata))
    }
    
    /// Extract text dari HTML menggunakan scraper
    fn extract_text_from_html(html: &str) -> Result<String> {
        let document = Html::parse_document(html);
        
        // Remove script dan style tags
        let body_selector = Selector::parse("body").unwrap();
        let script_selector = Selector::parse("script, style").unwrap();
        
        let mut text = String::new();
        
        for element in document.select(&body_selector) {
            let html_text = element.html();
            let doc = Html::parse_fragment(&html_text);
            
            // Remove scripts/styles
            for elem in doc.select(&script_selector) {
                // Skip these elements
                continue;
            }
            
            // Extract text
            text.push_str(&element.text().collect::<String>());
        }
        
        // Cleanup: remove excessive whitespace
        let cleaned = text
            .lines()
            .map(|l| l.trim())
            .filter(|l| !l.is_empty())
            .collect::<Vec<_>>()
            .join("\n");
        
        Ok(cleaned)
    }
    
    /// Parse plain text
    fn parse_text(path: &Path) -> Result<(String, DocumentMetadata)> {
        let raw_content = fs::read(path)?;
        let (content, encoding) = Self::decode_text(&raw_content)?;
        
        let metadata = DocumentMetadata {
            file_type: "text/plain".to_string(),
            pages: None,
            char_count: content.len(),
            encoding: encoding.to_string(),
        };
        
        Ok((content, metadata))
    }
    
    /// Decode text dengan encoding detection
    fn decode_text(bytes: &[u8]) -> Result<(String, &'static Encoding)> {
        // Try UTF-8 first
        if let Ok(text) = std::str::from_utf8(bytes) {
            return Ok((text.to_string(), UTF_8));
        }
        
        // Auto-detect encoding
        let (encoding, _, _) = UTF_8.decode(bytes);
        
        Ok((encoding.to_string(), UTF_8))
    }
}
```

**`src/document/chunker.rs`**

```rust
use crate::config::ChunkStrategy;
use anyhow::Result;
use text_splitter::{ChunkConfig, TextSplitter};
use tracing::debug;

#[derive(Debug, Clone)]
pub struct Chunk {
    pub index: usize,
    pub content: String,
    pub char_count: usize,
    pub token_count: Option<usize>,
}

pub struct TextChunker {
    chunk_size: usize,
    chunk_overlap: usize,
    strategy: ChunkStrategy,
}

impl TextChunker {
    pub fn new(chunk_size: usize, chunk_overlap: usize, strategy: ChunkStrategy) -> Self {
        Self {
            chunk_size,
            chunk_overlap,
            strategy,
        }
    }
    
    /// Chunk text into smaller pieces
    pub fn chunk(&self, text: &str) -> Result<Vec<Chunk>> {
        if text.trim().is_empty() {
            return Ok(Vec::new());
        }
        
        debug!("Chunking text: {} chars", text.len());
        
        let chunks = match self.strategy {
            ChunkStrategy::Semantic => self.chunk_semantic(text)?,
            ChunkStrategy::Fixed => self.chunk_fixed(text)?,
            ChunkStrategy::Recursive => self.chunk_recursive(text)?,
        };
        
        debug!("Created {} chunks", chunks.len());
        
        Ok(chunks)
    }
    
    /// Semantic chunking (best untuk RAG)
    fn chunk_semantic(&self, text: &str) -> Result<Vec<Chunk>> {
        let splitter = TextSplitter::new(
            ChunkConfig::new(self.chunk_size)
                .with_overlap(self.chunk_overlap)
                .unwrap()
        );
        
        let chunk_texts: Vec<&str> = splitter.chunks(text).collect();
        
        let chunks = chunk_texts
            .into_iter()
            .enumerate()
            .map(|(i, content)| Chunk {
                index: i,
                content: content.to_string(),
                char_count: content.len(),
                token_count: None, // bisa di-calculate kalau perlu
            })
            .collect();
        
        Ok(chunks)
    }
    
    /// Fixed size chunking
    fn chunk_fixed(&self, text: &str) -> Result<Vec<Chunk>> {
        let mut chunks = Vec::new();
        let chars: Vec<char> = text.chars().collect();
        let total_chars = chars.len();
        
        let mut start = 0;
        let mut index = 0;
        
        while start < total_chars {
            let end = (start + self.chunk_size).min(total_chars);
            let content: String = chars[start..end].iter().collect();
            
            chunks.push(Chunk {
                index,
                content,
                char_count: end - start,
                token_count: None,
            });
            
            index += 1;
            start += self.chunk_size - self.chunk_overlap;
            
            if start >= total_chars {
                break;
            }
        }
        
        Ok(chunks)
    }
    
    /// Recursive character splitting
    fn chunk_recursive(&self, text: &str) -> Result<Vec<Chunk>> {
        // Split by paragraphs first
        let paragraphs: Vec<&str> = text
            .split("\n\n")
            .filter(|p| !p.trim().is_empty())
            .collect();
        
        let mut chunks = Vec::new();
        let mut current_chunk = String::new();
        let mut index = 0;
        
        for para in paragraphs {
            // If adding this paragraph exceeds chunk size, save current chunk
            if !current_chunk.is_empty() 
                && current_chunk.len() + para.len() > self.chunk_size 
            {
                chunks.push(Chunk {
                    index,
                    content: current_chunk.clone(),
                    char_count: current_chunk.len(),
                    token_count: None,
                });
                
                index += 1;
                
                // Start new chunk with overlap dari chunk sebelumnya
                let overlap_chars: String = current_chunk
                    .chars()
                    .rev()
                    .take(self.chunk_overlap)
                    .collect::<String>()
                    .chars()
                    .rev()
                    .collect();
                
                current_chunk = overlap_chars;
            }
            
            current_chunk.push_str(para);
            current_chunk.push_str("\n\n");
        }
        
        // Add last chunk
        if !current_chunk.is_empty() {
            chunks.push(Chunk {
                index,
                content: current_chunk.clone(),
                char_count: current_chunk.len(),
                token_count: None,
            });
        }
        
        Ok(chunks)
    }
}
```

**ðŸ“Œ Referensi:** [Text chunking strategies for RAG](https://www.linkedin.com/pulse/improving-text-chunking-rag-rust-shelby-jenkins--bgj5c), [lopdf PDF parsing](https://github.com/J-F-Liu/lopdf) [linkedin](https://www.linkedin.com/pulse/improving-text-chunking-rag-rust-shelby-jenkins--bgj5c)
