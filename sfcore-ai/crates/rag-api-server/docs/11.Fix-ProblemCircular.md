## ğŸ”§ LANJUT FIXES - PART 2

***

### **STEP 6: UPDATE `Cargo.toml`** (Add async-trait)

```toml
[dependencies]
# ... existing dependencies ...

# === NEW: For trait abstraction ===
async-trait = "0.1"

# ... rest of dependencies ...
```

***

### **STEP 7: FIXED `src/services/embedding.rs`**

```rust
use anyhow::{Context, Result};
use reqwest::Client;
use serde::{Deserialize, Serialize};
use tracing::{debug, error};

// Import trait from conversation module
use crate::services::conversation::manager::EmbeddingProvider;

#[derive(Clone)]
pub struct EmbeddingService {
    client: Client,
    base_url: String,
}

impl EmbeddingService {
    pub fn new(base_url: &str) -> Result<Self> {
        Ok(Self {
            client: Client::builder()
                .timeout(std::time::Duration::from_secs(30))
                .build()
                .context("Failed to create HTTP client")?,
            base_url: base_url.to_string(),
        })
    }

    /// Internal method for embedding (used by trait implementation)
    async fn embed_internal(&self, text: &str) -> Result<Vec<f32>> {
        #[derive(Serialize)]
        struct EmbedRequest {
            input: String,
        }

        #[derive(Deserialize)]
        struct EmbedResponse {
            embedding: Vec<f32>,
        }

        let url = format!("{}/v1/embeddings", self.base_url);
        
        let response = self.client
            .post(&url)
            .json(&EmbedRequest {
                input: text.to_string(),
            })
            .send()
            .await
            .context("Failed to send embedding request")?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_default();
            anyhow::bail!("Embedding API error {}: {}", status, error_text);
        }

        let embed_response: EmbedResponse = response
            .json()
            .await
            .context("Failed to parse embedding response")?;

        debug!("Generated embedding with {} dimensions", embed_response.embedding.len());

        Ok(embed_response.embedding)
    }

    /// Internal method for weighted embedding
    async fn embed_weighted_internal(
        &self,
        current_text: &str,
        context_text: &str,
        current_weight: f32,
        history_weight: f32,
    ) -> Result<Vec<f32>> {
        // Embed current message
        let current_embedding = self.embed_internal(current_text).await?;
        
        // Embed full context
        let context_embedding = self.embed_internal(context_text).await?;
        
        // Weighted average
        let weighted = current_embedding
            .iter()
            .zip(context_embedding.iter())
            .map(|(curr, ctx)| {
                current_weight * curr + history_weight * ctx
            })
            .collect();
        
        debug!("Generated weighted embedding (current: {}, history: {})", 
            current_weight, history_weight);

        Ok(weighted)
    }
}

// Implement the trait for ConversationManager to use
#[async_trait::async_trait]
impl EmbeddingProvider for EmbeddingService {
    async fn embed(&self, text: &str) -> Result<Vec<f32>> {
        self.embed_internal(text).await
    }

    async fn embed_weighted(
        &self,
        current_text: &str,
        context_text: &str,
        current_weight: f32,
        history_weight: f32,
    ) -> Result<Vec<f32>> {
        self.embed_weighted_internal(current_text, context_text, current_weight, history_weight).await
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    #[ignore] // Requires running llama-server
    async fn test_embed() {
        let service = EmbeddingService::new("http://127.0.0.1:8080").unwrap();
        let result = service.embed_internal("test").await;
        assert!(result.is_ok());
    }
}
```

***

### **STEP 8: FIXED `src/services/llm.rs`**

```rust
use anyhow::{Context, Result};
use reqwest::Client;
use serde::{Deserialize, Serialize};
use tracing::{debug, error, warn};

use crate::models::chat::ChatMessage;
use crate::services::conversation::manager::{LlmProvider, RetrievalChunk};

#[derive(Clone)]
pub struct LlmService {
    client: Client,
    base_url: String,
}

impl LlmService {
    pub fn new(base_url: &str) -> Result<Self> {
        Ok(Self {
            client: Client::builder()
                .timeout(std::time::Duration::from_secs(300))
                .build()
                .context("Failed to create HTTP client")?,
            base_url: base_url.to_string(),
        })
    }

    /// Internal method for text generation
    async fn generate_internal(&self, messages: &[ChatMessage]) -> Result<String> {
        #[derive(Serialize)]
        struct CompletionRequest {
            messages: Vec<ChatMessage>,
            stream: bool,
            max_tokens: i32,
        }

        #[derive(Deserialize)]
        struct CompletionResponse {
            choices: Vec<Choice>,
        }

        #[derive(Deserialize)]
        struct Choice {
            message: MessageContent,
        }

        #[derive(Deserialize)]
        struct MessageContent {
            content: String,
        }

        let url = format!("{}/v1/chat/completions", self.base_url);
        
        let response = self.client
            .post(&url)
            .json(&CompletionRequest {
                messages: messages.to_vec(),
                stream: false,
                max_tokens: 2048,
            })
            .send()
            .await
            .context("Failed to send LLM request")?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_default();
            anyhow::bail!("LLM API error {}: {}", status, error_text);
        }

        let completion: CompletionResponse = response
            .json()
            .await
            .context("Failed to parse LLM response")?;

        let content = completion
            .choices
            .first()
            .map(|c| c.message.content.clone())
            .context("No response from LLM")?;

        debug!("Generated response with {} chars", content.len());

        Ok(content)
    }

    /// Internal method for chunk summarization
    async fn summarize_chunks_internal(&self, chunks: &[RetrievalChunk]) -> Result<String> {
        if chunks.is_empty() {
            return Ok("No relevant documents found.".to_string());
        }

        let chunks_text: String = chunks
            .iter()
            .enumerate()
            .map(|(i, chunk)| {
                format!(
                    "[Chunk {}]\nDocument: {}\nContent: {}\n",
                    i + 1,
                    chunk.document_title.as_deref().unwrap_or("Unknown"),
                    chunk.content
                )
            })
            .collect::<Vec<_>>()
            .join("\n");

        let summarization_prompt = format!(
            r#"Summarize the following document chunks into a concise context (max 300 words).
Focus on key information that would help answer user questions.

{}

Provide a clear, structured summary:"#,
            chunks_text
        );

        const MAX_RETRIES: u32 = 3;
        
        for attempt in 1..=MAX_RETRIES {
            let messages = vec![
                ChatMessage::system("You are a document summarization assistant."),
                ChatMessage::user(&summarization_prompt),
            ];

            match self.generate_internal(&messages).await {
                Ok(summary) => {
                    debug!("Chunk summarization succeeded on attempt {}", attempt);
                    return Ok(summary);
                }
                Err(e) => {
                    if attempt < MAX_RETRIES {
                        warn!("Summarization failed (attempt {}): {}", attempt, e);
                        tokio::time::sleep(tokio::time::Duration::from_secs(attempt as u64)).await;
                    } else {
                        error!("Summarization failed after {} attempts", MAX_RETRIES);
                        // Fallback: return raw chunks
                        return Ok(chunks_text);
                    }
                }
            }
        }

        unreachable!()
    }
}

// Implement the trait
#[async_trait::async_trait]
impl LlmProvider for LlmService {
    async fn generate(&self, messages: &[ChatMessage]) -> Result<String> {
        self.generate_internal(messages).await
    }

    async fn summarize_chunks(&self, chunks: &[RetrievalChunk]) -> Result<String> {
        self.summarize_chunks_internal(chunks).await
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    #[ignore]
    async fn test_generate() {
        let service = LlmService::new("http://127.0.0.1:8080").unwrap();
        let messages = vec![
            ChatMessage::system("You are a helpful assistant"),
            ChatMessage::user("Hello"),
        ];
        let result = service.generate_internal(&messages).await;
        assert!(result.is_ok());
    }
}
```

***

### **STEP 9: FIXED `src/services/retrieval.rs`**

```rust
use anyhow::{Context, Result};
use sqlx::PgPool;
use tracing::debug;

use crate::services::conversation::manager::{RetrievalProvider, RetrievalChunk};

#[derive(Clone)]
pub struct RetrievalService {
    pool: PgPool,
}

impl RetrievalService {
    pub fn new(pool: PgPool) -> Self {
        Self { pool }
    }

    /// Internal method for retrieval
    async fn search_internal(
        &self,
        user_id: i64,
        embedding: &[f32],
        document_id: Option<i64>,
        limit: i32,
    ) -> Result<Vec<RetrievalChunk>> {
        let embedding_str = format!("[{}]", 
            embedding.iter()
                .map(|f| f.to_string())
                .collect::<Vec<_>>()
                .join(",")
        );

        // Query using vw_user_documents for security
        let query = if let Some(doc_id) = document_id {
            sqlx::query_as!(
                RetrievalChunkRow,
                r#"
                SELECT 
                    c.id as chunk_id,
                    c.document_id,
                    d.document_title,
                    c.content,
                    1 - (c.embedding <=> $1::vector) as similarity
                FROM rag_document_chunks c
                INNER JOIN vw_user_documents d ON c.document_id = d.document_id
                WHERE d.user_id = $2 AND d.document_id = $3
                ORDER BY c.embedding <=> $1::vector
                LIMIT $4
                "#,
                embedding_str,
                user_id,
                doc_id,
                limit
            )
        } else {
            sqlx::query_as!(
                RetrievalChunkRow,
                r#"
                SELECT 
                    c.id as chunk_id,
                    c.document_id,
                    d.document_title,
                    c.content,
                    1 - (c.embedding <=> $1::vector) as similarity
                FROM rag_document_chunks c
                INNER JOIN vw_user_documents d ON c.document_id = d.document_id
                WHERE d.user_id = $2
                ORDER BY c.embedding <=> $1::vector
                LIMIT $3
                "#,
                embedding_str,
                user_id,
                limit
            )
        };

        let rows = query
            .fetch_all(&self.pool)
            .await
            .context("Failed to execute retrieval query")?;

        debug!("Retrieved {} chunks for user {}", rows.len(), user_id);

        let chunks = rows
            .into_iter()
            .map(|row| RetrievalChunk {
                chunk_id: row.chunk_id,
                document_id: row.document_id,
                document_title: row.document_title,
                content: row.content,
                similarity: row.similarity,
            })
            .collect();

        Ok(chunks)
    }
}

// Database row type
#[derive(Debug)]
struct RetrievalChunkRow {
    chunk_id: i64,
    document_id: i64,
    document_title: Option<String>,
    content: String,
    similarity: f32,
}

// Implement the trait
#[async_trait::async_trait]
impl RetrievalProvider for RetrievalService {
    async fn search(
        &self,
        user_id: i64,
        embedding: &[f32],
        document_id: Option<i64>,
    ) -> Result<Vec<RetrievalChunk>> {
        self.search_internal(user_id, embedding, document_id, 5).await
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    #[ignore]
    async fn test_search() {
        // Requires database setup
    }
}
```

***

### **STEP 10: FIXED `src/services/conversation/mod.rs`**

```rust
//! Conversation memory management module

mod cache;
mod context_builder;
pub mod manager;  // Make public for trait access
mod token_counter;
pub mod types;

pub use cache::{ConversationCache, CacheStats};
pub use context_builder::ContextBuilder;
pub use manager::ConversationManager;
pub use token_counter::TokenCounter;
pub use types::{
    ConversationState, RetrievalDecision,
    SystemContextComponents, WeightedEmbeddingConfig,
};
```

***

### **STEP 11: FIXED `src/services/mod.rs`**

```rust
pub mod conversation;
pub mod embedding;
pub mod llm;
pub mod retrieval;

// Re-exports
pub use conversation::ConversationManager;
pub use embedding::EmbeddingService;
pub use llm::LlmService;
pub use retrieval::RetrievalService;
```

***

### **STEP 12: FIXED `src/handlers/chat.rs`**

```rust
use axum::{
    extract::State,
    response::sse::{Event, KeepAlive, Sse},
    Json,
};
use futures::stream::{self, Stream};
use std::convert::Infallible;
use std::sync::Arc;
use tracing::{error, info};

use crate::models::chat::{ChatRequest, SessionId};
use crate::services::conversation::ConversationManager;
use crate::AppState;

/// Handle streaming chat request
pub async fn chat_stream_handler(
    State(state): State<Arc<AppState>>,
    Json(req): Json<ChatRequest>,
) -> Result<Sse<impl Stream<Item = Result<Event, Infallible>>>, (axum::http::StatusCode, String)> {
    info!(
        "Chat stream request: session_id={}, user_id={}, document_id={:?}",
        req.session_id, req.user_id, req.document_id
    );

    if req.message.trim().is_empty() {
        return Err((
            axum::http::StatusCode::BAD_REQUEST,
            "Message cannot be empty".to_string(),
        ));
    }

    let conversation_manager = state.conversation_manager.clone();
    let session_id = req.session_id;
    let user_id = req.user_id;
    let message = req.message.clone();
    let document_id = req.document_id;

    let stream = stream::unfold(
        (conversation_manager, session_id, user_id, message, document_id, false),
        |(manager, session_id, user_id, message, document_id, mut done)| async move {
            if done {
                return None;
            }

            match manager.handle_message(session_id, user_id, message, document_id).await {
                Ok(response) => {
                    done = true;
                    
                    let message_event = Event::default()
                        .event("message")
                        .data(response);
                    
                    Some((
                        Ok(message_event),
                        (manager, session_id, user_id, String::new(), document_id, done),
                    ))
                }
                Err(e) => {
                    error!("Error handling message: {}", e);
                    done = true;
                    
                    let error_event = Event::default()
                        .event("error")
                        .data(format!("{{\"message\": \"{}\"}}", e));
                    
                    Some((
                        Ok(error_event),
                        (manager, session_id, user_id, String::new(), document_id, done),
                    ))
                }
            }
        },
    );

    Ok(Sse::new(stream).keep_alive(KeepAlive::default()))
}

/// Generate new session ID
#[derive(serde::Deserialize)]
pub struct NewSessionRequest {
    pub user_id: i64,
}

#[derive(serde::Serialize)]
pub struct NewSessionResponse {
    pub session_id: SessionId,
}

pub async fn new_session_handler(
    Json(req): Json<NewSessionRequest>,
) -> Result<Json<NewSessionResponse>, (axum::http::StatusCode, String)> {
    let session_id = ConversationManager::generate_session_id(req.user_id);
    
    info!("Generated new session ID {} for user {}", session_id, req.user_id);
    
    Ok(Json(NewSessionResponse { session_id }))
}

/// Get cache statistics
#[derive(serde::Serialize)]
pub struct CacheStatsResponse {
    pub active_sessions: usize,
    pub memory_usage_mb: u64,
    pub memory_total_mb: u64,
    pub memory_usage_percent: f64,
}

pub async fn cache_stats_handler(
    State(state): State<Arc<AppState>>,
) -> Json<CacheStatsResponse> {
    let stats = state.conversation_manager.cache_stats();
    
    Json(CacheStatsResponse {
        active_sessions: stats.active_sessions,
        memory_usage_mb: stats.memory_usage_mb,
        memory_total_mb: stats.memory_total_mb,
        memory_usage_percent: stats.memory_usage_percent,
    })
}

/// Manual cleanup
#[derive(serde::Serialize)]
pub struct CleanupResponse {
    pub sessions_removed: usize,
}

pub async fn cleanup_sessions_handler(
    State(state): State<Arc<AppState>>,
) -> Json<CleanupResponse> {
    let count = state.conversation_manager.cleanup_expired_sessions();
    
    info!("Manual cleanup removed {} expired sessions", count);
    
    Json(CleanupResponse {
        sessions_removed: count,
    })
}
```

***

### **STEP 13: FIXED `src/main.rs`**

```rust
use std::sync::Arc;
use axum::{
    routing::{get, post},
    Router,
};
use sqlx::PgPool;
use tower_http::cors::CorsLayer;
use tracing::info;

mod auth;
mod config;
mod database;
mod document;
mod handlers;
mod models;
mod security;
mod services;
mod utils;

use config::Settings;
use services::{
    conversation::ConversationManager,
    embedding::EmbeddingService,
    llm::LlmService,
    retrieval::RetrievalService,
};

pub struct AppState {
    pub db_pool: PgPool,
    pub conversation_manager: Arc<ConversationManager>,
    pub settings: Settings,
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    tracing_subscriber::fmt()
        .with_env_filter(
            std::env::var("RUST_LOG")
                .unwrap_or_else(|_| "info,rag_api_server=debug".to_string()),
        )
        .init();

    info!("Starting RAG API Server with Conversation Memory...");

    let settings = Settings::load()?;
    info!("Configuration loaded");

    let db_pool = PgPool::connect(&settings.database.url).await?;
    info!("Database connection pool initialized");

    // Initialize services
    let embedding_service = EmbeddingService::new(&settings.llm.base_url)?;
    let retrieval_service = RetrievalService::new(db_pool.clone());
    let llm_service = LlmService::new(&settings.llm.base_url)?;
    
    // Initialize conversation manager with trait objects (no circular dependency!)
    let conversation_manager = Arc::new(ConversationManager::new(
        Box::new(embedding_service),
        Box::new(retrieval_service),
        Box::new(llm_service),
    ));
    
    info!("Conversation manager initialized");

    let app_state = Arc::new(AppState {
        db_pool,
        conversation_manager,
        settings: settings.clone(),
    });

    let app = Router::new()
        .route("/health", get(handlers::health::health_check))
        .route("/api/chat/stream", post(handlers::chat::chat_stream_handler))
        .route("/api/chat/session/new", post(handlers::chat::new_session_handler))
        .route("/api/chat/stats", get(handlers::chat::cache_stats_handler))
        .route("/api/chat/cleanup", post(handlers::chat::cleanup_sessions_handler))
        .with_state(app_state)
        .layer(CorsLayer::permissive());

    let addr = format!("{}:{}", settings.server.host, settings.server.port);
    info!("Server listening on {}", addr);

    let listener = tokio::net::TcpListener::bind(&addr).await?;
    axum::serve(listener, app).await?;

    Ok(())
}
```

***

### **STEP 14: ADD `src/database/mod.rs`** (jika belum ada)

```rust
use sqlx::PgPool;

pub type DatabasePool = PgPool;

// Re-export common types if needed
```

***

### **STEP 15: ADD `src/config/mod.rs`** (jika belum ada)

```rust
use serde::Deserialize;
use anyhow::Result;

#[derive(Debug, Clone, Deserialize)]
pub struct Settings {
    pub server: ServerSettings,
    pub database: DatabaseSettings,
    pub llm: LlmSettings,
    pub security: SecuritySettings,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ServerSettings {
    pub host: String,
    pub port: u16,
}

#[derive(Debug, Clone, Deserialize)]
pub struct DatabaseSettings {
    pub url: String,
}

#[derive(Debug, Clone, Deserialize)]
pub struct LlmSettings {
    pub base_url: String,
}

#[derive(Debug, Clone, Deserialize)]
pub struct SecuritySettings {
    pub allowed_ips: Vec<String>,
}

impl Settings {
    pub fn load() -> Result<Self> {
        // Load from config file or environment
        // Placeholder implementation
        Ok(Self {
            server: ServerSettings {
                host: "0.0.0.0".to_string(),
                port: 8000,
            },
            database: DatabaseSettings {
                url: std::env::var("DATABASE_URL")
                    .unwrap_or_else(|_| "postgres://localhost/db".to_string()),
            },
            llm: LlmSettings {
                base_url: std::env::var("LLM_BASE_URL")
                    .unwrap_or_else(|_| "http://127.0.0.1:8080".to_string()),
            },
            security: SecuritySettings {
                allowed_ips: vec!["127.0.0.1".to_string()],
            },
        })
    }
}
```

***

## âœ… CIRCULAR DEPENDENCY FIXED

### **Struktur Dependency yang Benar Sekarang:**

```
models/chat.rs (ChatMessage, SessionId)
    â†‘
    â”‚ (import)
    â”‚
services/conversation/types.rs
    â†‘
    â”‚
services/conversation/manager.rs (defines traits)
    â†‘
    â”‚ (implements traits)
    â”‚
services/embedding.rs
services/llm.rs
services/retrieval.rs
    â†‘
    â”‚ (inject via Box<dyn Trait>)
    â”‚
main.rs
```

### **Key Changes yang Memecahkan Circular Dependency:**

1. âœ… **ChatMessage moved to `models/chat.rs`** - shared across all modules
2. âœ… **Traits defined in `manager.rs`** - abstraction layer
3. âœ… **Services implement traits** - no direct dependency on conversation types
4. âœ… **Dependency injection via Box<dyn Trait>** - runtime polymorphism
5. âœ… **RetrievalChunk defined in manager.rs** - avoid cross-module dependency

***

## ğŸ§ª TEST BUILD

```bash
# Clean dan rebuild
cargo clean
cargo build --release

# Expected: Should compile without circular dependency errors! âœ…
```

***

## ğŸ“Š Module Dependency Graph (Fixed)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   models/chat.rs    â”‚
â”‚  (ChatMessage,      â”‚
â”‚   SessionId)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  services/conversation/types.rs     â”‚
â”‚  (ConversationState, TokenCount)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  services/conversation/manager.rs            â”‚
â”‚  (Traits: EmbeddingProvider,                 â”‚
â”‚   RetrievalProvider, LlmProvider)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼          â–¼          â–¼          â–¼
      embedding.rs  llm.rs  retrieval.rs  main.rs
      (implements   (impl    (impl        (inject
       trait)       trait)   trait)       via Box)
```

**NO MORE CYCLES! âœ…**

***

## ğŸ¯ Summary Fixes

| Issue | Solution |
|-------|----------|
| ChatMessage duplication | Moved to `models/chat.rs` (shared) |
| Circular service deps | Trait abstraction in manager.rs |
| Manager needs services | Dependency injection via `Box<dyn Trait>` |
| RetrievalChunk conflict | Defined in manager.rs, used by trait |
| Build errors | Clean module hierarchy |

***

**Build should pass now bro! Mau test compile?** ğŸš€ğŸ¦€
