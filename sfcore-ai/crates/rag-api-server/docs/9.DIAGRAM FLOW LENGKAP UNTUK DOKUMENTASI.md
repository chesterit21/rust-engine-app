## ğŸ“Š MERMAID DIAGRAM FLOW LENGKAP UNTUK DOKUMENTASI

***

## ğŸ¨ DIAGRAM 1: HIGH-LEVEL SYSTEM ARCHITECTURE

```mermaid
graph TB
    subgraph Client["Client Application"]
        UI[React UI]
        ChatComp[Chat Component]
        FileUpload[File Upload]
    end

    subgraph APIServer["RAG API Server (Rust + Axum)"]
        subgraph SecurityLayer["Security Layer"]
            IPWhitelist[IP Whitelist Checker]
            HeaderValidation[Custom Headers Validator]
            HMACVerify[HMAC Signature Verifier]
        end

        subgraph HandlerLayer["Handler Layer"]
            ChatHandler[Chat Handler]
            SearchHandler[Search Handler]
            UploadHandler[Upload Handler]
            StatsHandler[Stats Handler]
        end

        subgraph ConversationModule["Conversation Memory Module"]
            ConvManager[Conversation Manager]
            MemCache[Memory Cache - DashMap]
            ContextBuilder[Context Builder]
            TokenCounter[Token Counter]
        end

        subgraph ServiceLayer["Service Layer"]
            EmbedSvc[Embedding Service]
            RetrievalSvc[Retrieval Service]
            LLMSvc[LLM Service]
        end

        subgraph UtilLayer["Utility Layer"]
            Similarity[Cosine Similarity]
            Tokenizer[Token Estimator]
        end
    end

    subgraph DataLayer["Data Layer"]
        PostgreSQL[(PostgreSQL + pgvector)]
        ViewUserDocs[vw_user_documents]
        ChunksTable[rag_document_chunks]
    end

    subgraph AIModels["AI Models"]
        LlamaServer[llama-server]
        EmbedModel[Embedding Model<br/>all-MiniLM-L6-v2]
        LLMModel[LLM Model<br/>Llama 3.2 / Qwen]
    end

    %% Client to API
    UI --> ChatComp
    UI --> FileUpload
    ChatComp -->|POST /api/chat/stream| SecurityLayer
    FileUpload -->|POST /api/upload| SecurityLayer

    %% Security to Handlers
    SecurityLayer --> ChatHandler
    SecurityLayer --> SearchHandler
    SecurityLayer --> UploadHandler
    SecurityLayer --> StatsHandler

    %% Handlers to Services
    ChatHandler --> ConvManager
    SearchHandler --> RetrievalSvc
    UploadHandler --> EmbedSvc

    %% Conversation Module Internal
    ConvManager --> MemCache
    ConvManager --> ContextBuilder
    ConvManager --> TokenCounter
    ConvManager --> EmbedSvc
    ConvManager --> RetrievalSvc
    ConvManager --> LLMSvc

    %% Context Builder to Utils
    ContextBuilder --> Similarity
    ContextBuilder --> Tokenizer

    %% Services to Data/AI
    EmbedSvc --> LlamaServer
    RetrievalSvc --> PostgreSQL
    LLMSvc --> LlamaServer

    %% Data Layer
    PostgreSQL --> ViewUserDocs
    PostgreSQL --> ChunksTable

    %% AI Models
    LlamaServer --> EmbedModel
    LlamaServer --> LLMModel

    %% Styling
    classDef security fill:#ff6b6b,stroke:#c92a2a,color:#fff
    classDef handler fill:#4dabf7,stroke:#1971c2,color:#fff
    classDef service fill:#51cf66,stroke:#2b8a3e,color:#fff
    classDef memory fill:#ffd43b,stroke:#f59f00,color:#000
    classDef data fill:#9775fa,stroke:#5f3dc4,color:#fff
    classDef ai fill:#ff8787,stroke:#c92a2a,color:#fff

    class SecurityLayer security
    class HandlerLayer handler
    class ServiceLayer,UtilLayer service
    class ConversationModule memory
    class DataLayer data
    class AIModels ai
```

***

## ğŸ¨ DIAGRAM 2: DETAILED MESSAGE FLOW (COMPLETE LIFECYCLE)

```mermaid
sequenceDiagram
    autonumber
    participant Client as ğŸ‘¤ Client
    participant Security as ğŸ” Security Middleware
    participant Handler as ğŸ¯ Chat Handler
    participant Manager as ğŸ§  Conversation Manager
    participant Cache as ğŸ’¾ Memory Cache
    participant Window as ğŸ“ Sliding Window
    participant Context as ğŸ—ï¸ Context Builder
    participant Token as ğŸ”¢ Token Counter
    participant Embed as ğŸ¨ Embedding Service
    participant Retrieval as ğŸ” Retrieval Service
    participant LLM as ğŸ¤– LLM Service
    participant DB as ğŸ—„ï¸ PostgreSQL

    %% Request Phase
    Client->>Security: POST /api/chat/stream<br/>{session_id, user_id, message, doc_id}
    Security->>Security: âœ“ IP Whitelist Check
    Security->>Security: âœ“ Custom Headers Validation
    Security->>Security: âœ“ Timestamp & HMAC Verify
    Security->>Handler: Request Authorized âœ“

    %% Session Management Phase
    Handler->>Manager: handle_message(session_id, user_id, message, doc_id)
    Manager->>Cache: get_or_create_session(session_id)
    
    alt Session Exists & Not Expired
        Cache-->>Manager: Return ConversationState
    else New Session or Expired
        Cache->>Cache: Check RAM Usage (must be < 90%)
        Cache->>Cache: Create New ConversationState
        Cache-->>Manager: Return New State
    end

    %% Sliding Window Enforcement
    Manager->>Window: enforce_sliding_window(state)
    Window->>Window: Check: message_pairs >= 5?
    
    alt >= 5 Pairs (ALWAYS DELETE)
        Window->>Window: Delete Q1, A1 (oldest pair)
        Note over Window: ğŸ—‘ï¸ ALWAYS enforce max 5 pairs<br/>regardless of token count
    end
    Window-->>Manager: Window Enforced âœ“

    %% Embedding Current Message
    Manager->>Embed: embed(current_message)
    Embed->>LLM: POST /embeddings
    LLM-->>Embed: embedding_vector [384 dims]
    Embed-->>Manager: current_embedding

    %% Retrieval Decision Phase
    Manager->>Context: decide_retrieval(state, message, doc_id, embedding)
    
    Context->>Context: Check: First message?
    alt First Message
        Context-->>Manager: âœ“ RETRIEVE (reason: FirstMessage)
    else Has History
        Context->>Context: Check: document_id changed?
        alt Document ID Changed
            Context-->>Manager: âœ“ RETRIEVE (reason: DocumentIdChanged)
        else Same Document ID
            Context->>Context: Calculate cosine_similarity(current, last)
            Context->>Context: Check: similarity > 0.75?
            alt Similarity > 0.75 (AND same doc_id)
                Context-->>Manager: âœ— SKIP (reason: HighSimilarity)
            else Similarity <= 0.75
                Context-->>Manager: âœ“ RETRIEVE (reason: LowSimilarity)
            end
        end
    end

    %% Retrieval Execution Phase
    alt Decision: SKIP Retrieval
        Manager->>Manager: Reuse previous system_context
        Note over Manager: ğŸ“‹ Reuse last retrieval results<br/>No DB/LLM calls
    else Decision: RETRIEVE
        alt Context-Aware Retrieval (has history)
            Manager->>Context: prepare_context_aware_text(message, history)
            Context->>Context: Extract last N user messages
            Context->>Context: Concatenate: "history + current"
            Context-->>Manager: context_text
            
            Manager->>Embed: embed_weighted(message, context_text, config)
            Note over Embed: Weighted: 0.7 * current + 0.3 * history
            Embed-->>Manager: weighted_embedding
        else Simple Retrieval (first message)
            Manager->>Manager: Use current_embedding directly
        end

        Manager->>Retrieval: search(user_id, embedding, doc_id)
        Retrieval->>DB: SELECT * FROM vw_user_documents<br/>ORDER BY embedding <=> query<br/>LIMIT 5
        DB-->>Retrieval: Top-K chunks (authorized only)
        Retrieval-->>Manager: retrieval_chunks[]

        Manager->>LLM: summarize_chunks(chunks) with RETRY 3x
        LLM->>LLM: Build summarization prompt
        LLM->>LLM: POST /v1/chat/completions
        
        alt LLM Success
            LLM-->>Manager: summary_text
        else LLM Failed (3 retries)
            LLM-->>Manager: Fallback: raw chunks text
        end

        Manager->>Context: build_system_context(summary, doc_metadata)
        Context->>Context: Combine: base_instruction + summary + metadata
        Context-->>Manager: new_system_context
        
        Manager->>Manager: Update state.system_context
        Manager->>Manager: Update state.last_retrieval_summary
    end

    %% Append User Message
    Manager->>Manager: messages.push(ChatMessage::user(message))

    %% Token Management Phase
    Manager->>Token: count_payload(system_context, messages, current_msg)
    Token->>Token: Count system tokens (randomize 2-3 chars/token)
    Token->>Token: Count history tokens
    Token->>Token: Count current message tokens
    Token-->>Manager: TokenCount {total, system, history, current}

    alt Total > 20K (Soft Limit)
        Note over Manager: âš ï¸ Token overflow detected

        loop Cascade Deletion (while total > 20K && messages.len >= 2)
            Manager->>Manager: Delete oldest pair (Q1, A1)
            Manager->>Token: Re-count tokens
            Token-->>Manager: new_total
        end

        alt Still > 23K (Hard Limit)
            Manager->>Manager: Truncate retrieval_summary (first 500 chars)
            Manager->>Context: rebuild_system_context(truncated_summary)
            Context-->>Manager: truncated_system_context
            Note over Manager: ğŸ”ª Forced truncation to fit 23K limit
        end
    end

    %% LLM Call Phase
    Manager->>Manager: Prepare LLM payload:<br/>[{system}, {user}, {assistant}, ...]
    Manager->>LLM: generate(messages) with RETRY 3x

    loop Retry up to 3 times
        LLM->>LLM: POST /v1/chat/completions (streaming)
        alt LLM Success
            LLM-->>Manager: assistant_response (text)
        else LLM Failed
            alt Retry < 3
                LLM->>LLM: Sleep & Retry
            else Retry = 3
                LLM-->>Manager: Error: "Server ada gangguan"
            end
        end
    end

    %% Save Response Phase
    Manager->>Manager: messages.push(ChatMessage::assistant(response))
    Manager->>Manager: last_query_embedding = current_embedding
    Manager->>Manager: metadata.total_messages += 2
    Manager->>Manager: touch() - update last_activity

    Manager->>Cache: set(session_id, updated_state)
    Cache-->>Manager: State Saved âœ“

    %% Response to Client
    Manager-->>Handler: assistant_response
    Handler->>Handler: Build SSE events
    Handler-->>Client: event: message<br/>data: {response}
    Handler-->>Client: event: done<br/>data: [DONE]

    Note over Client,DB: âœ… Conversation complete!<br/>Next message will reuse this context<br/>if document_id same & similarity > 0.75
```

***

## ğŸ¨ DIAGRAM 3: RETRIEVAL DECISION TREE

```mermaid
flowchart TD
    Start([New Message Arrives]) --> FirstCheck{Is this<br/>FIRST message<br/>in session?}
    
    FirstCheck -->|YES| FirstRetrieval[âœ… RETRIEVE<br/>Reason: FirstMessage<br/>Mode: Simple embedding]
    FirstCheck -->|NO| DocCheck{document_id<br/>CHANGED<br/>from previous?}
    
    DocCheck -->|YES| DocChangeRetrieval[âœ… RETRIEVE<br/>Reason: DocumentIdChanged<br/>Mode: Context-aware]
    DocCheck -->|NO| SameDoc[document_id: SAME âœ“]
    
    SameDoc --> CalcSim[Calculate Similarity:<br/>cosine_similarity<br/>current_emb vs last_emb]
    
    CalcSim --> SimCheck{similarity<br/>> 0.75?}
    
    SimCheck -->|YES| AndCheck[âœ“ document_id SAME<br/>AND<br/>âœ“ similarity > 0.75]
    SimCheck -->|NO| LowSim[similarity â‰¤ 0.75]
    
    AndCheck --> Skip[âŒ SKIP Retrieval<br/>Reason: HighSimilarity<br/>Action: Reuse previous context]
    LowSim --> LowSimRetrieval[âœ… RETRIEVE<br/>Reason: LowSimilarity<br/>Mode: Context-aware]
    
    %% Retrieval Path
    FirstRetrieval --> EmbedCurrent[Embed: current message only]
    DocChangeRetrieval --> EmbedWeighted[Embed: weighted<br/>current 0.7 + history 0.3]
    LowSimRetrieval --> EmbedWeighted
    
    EmbedCurrent --> SearchDB[Search PostgreSQL<br/>pgvector cosine similarity]
    EmbedWeighted --> SearchDB
    
    SearchDB --> GetChunks[Get Top-K chunks<br/>user-authorized only]
    GetChunks --> Summarize[LLM Summarization<br/>chunks â†’ concise context]
    Summarize --> BuildContext[Build NEW System Context<br/>base + summary + metadata]
    BuildContext --> UpdateState[Update State:<br/>system_context<br/>last_retrieval_summary<br/>last_query_embedding]
    
    %% Skip Path
    Skip --> ReuseContext[Reuse Existing:<br/>state.system_context<br/>state.last_retrieval_summary]
    ReuseContext --> NoUpdate[No State Updates<br/>metadata.retrieval_skipped_count++]
    
    %% End
    UpdateState --> End([Continue to Token Management])
    NoUpdate --> End

    %% Styling
    classDef retrieve fill:#51cf66,stroke:#2b8a3e,color:#fff,stroke-width:3px
    classDef skip fill:#ffd43b,stroke:#f59f00,color:#000,stroke-width:3px
    classDef decision fill:#4dabf7,stroke:#1971c2,color:#fff
    classDef process fill:#e0e0e0,stroke:#666,color:#000

    class FirstRetrieval,DocChangeRetrieval,LowSimRetrieval retrieve
    class Skip skip
    class FirstCheck,DocCheck,SimCheck decision
    class Start,End,CalcSim,EmbedCurrent,EmbedWeighted,SearchDB,GetChunks,Summarize,BuildContext,UpdateState,ReuseContext,NoUpdate process
```

***

## ğŸ¨ DIAGRAM 4: TOKEN MANAGEMENT & CASCADE DELETION

```mermaid
flowchart TD
    Start([Message Ready to Send]) --> EnforceWindow{Message history<br/>>= 5 pairs?}
    
    EnforceWindow -->|YES| ForceDelete[ğŸ—‘ï¸ FORCE DELETE<br/>Q1, A1 oldest pair<br/>ALWAYS regardless token count]
    EnforceWindow -->|NO| AppendMsg[Append User Message<br/>to history temporarily]
    
    ForceDelete --> AppendMsg
    
    AppendMsg --> BuildPayload[Build Complete Payload:<br/>system_context +<br/>messages history +<br/>current message]
    
    BuildPayload --> CountTokens[ğŸ”¢ Count Total Tokens<br/>Randomize: 2-3 chars = 1 token]
    
    CountTokens --> TokenResult[TokenCount:<br/>total, system, history, current]
    
    TokenResult --> Check20K{total<br/>> 20K?<br/>Soft Limit}
    
    Check20K -->|NO| Check23K{total<br/>> 23K?<br/>Hard Limit}
    Check20K -->|YES| StartCascade[âš ï¸ OVERFLOW DETECTED<br/>Start Cascade Deletion]
    
    StartCascade --> CascadeLoop{messages.len<br/>>= 2?}
    
    CascadeLoop -->|YES| DeleteOldest[Delete Oldest Pair<br/>messages.drain 0..2]
    CascadeLoop -->|NO| OnlyCurrentLeft[Only current message left<br/>All history deleted]
    
    DeleteOldest --> ReCount[Re-count Tokens]
    ReCount --> StillOver{total<br/>still > 20K?}
    
    StillOver -->|YES| CascadeLoop
    StillOver -->|NO| Check23KAfter{total<br/>> 23K?}
    
    OnlyCurrentLeft --> Check23KAfter
    
    Check23K -->|YES| TruncateNow[ğŸ”ª TRUNCATE RETRIEVAL<br/>Keep only first 500 chars<br/>+ ... truncated]
    Check23K -->|NO| PayloadOK[âœ… Payload Ready<br/>total <= 23K]
    
    Check23KAfter -->|YES| TruncateNow
    Check23KAfter -->|NO| PayloadOK
    
    TruncateNow --> RebuildContext[Rebuild System Context<br/>with truncated retrieval]
    RebuildContext --> PayloadOK
    
    PayloadOK --> UpdateCache[ğŸ’¾ Update Memory Cache<br/>with cleaned state]
    UpdateCache --> SendLLM([ğŸ¤– Send to LLM])

    %% Styling
    classDef danger fill:#ff6b6b,stroke:#c92a2a,color:#fff,stroke-width:3px
    classDef warning fill:#ffd43b,stroke:#f59f00,color:#000,stroke-width:3px
    classDef success fill:#51cf66,stroke:#2b8a3e,color:#fff,stroke-width:3px
    classDef decision fill:#4dabf7,stroke:#1971c2,color:#fff

    class ForceDelete,DeleteOldest,TruncateNow danger
    class StartCascade,ReCount,StillOver warning
    class PayloadOK,UpdateCache success
    class EnforceWindow,Check20K,Check23K,CascadeLoop,Check23KAfter decision
```

***

## ğŸ¨ DIAGRAM 5: SLIDING WINDOW VISUALIZATION

```mermaid
graph TD
    subgraph State1["Message 1-4: Normal State"]
        M1["Q1, A1<br/>Q2, A2<br/>Q3, A3<br/>Q4, A4<br/><br/>4 pairs âœ“<br/>Token: 10K"]
    end

    subgraph State2["Message 5: At Max"]
        M2["Q1, A1<br/>Q2, A2<br/>Q3, A3<br/>Q4, A4<br/>Q5, A5<br/><br/>5 pairs âœ“ MAX<br/>Token: 15K"]
    end

    subgraph State3["Message 6: Window Enforced"]
        M3["âŒ Q1, A1 DELETED<br/>Q2, A2<br/>Q3, A3<br/>Q4, A4<br/>Q5, A5<br/>Q6, A6<br/><br/>5 pairs âœ“<br/>Token: 18K"]
    end

    subgraph State4["Message 7: Continue Sliding"]
        M4["âŒ Q2, A2 DELETED<br/>Q3, A3<br/>Q4, A4<br/>Q5, A5<br/>Q6, A6<br/>Q7, A7<br/><br/>5 pairs âœ“<br/>Token: 19K"]
    end

    subgraph State5["Message 8: Token Overflow"]
        M5["âŒ Q3, A3 DELETED<br/>âŒ Q4, A4 DELETED cascade<br/>Q5, A5<br/>Q6, A6<br/>Q7, A7<br/>Q8, A8<br/><br/>4 pairs<br/>Token: 17K âœ“"]
    end

    State1 -->|Add Q5, A5| State2
    State2 -->|Add Q6, A6<br/>Enforce Window| State3
    State3 -->|Add Q7, A7<br/>Enforce Window| State4
    State4 -->|Add Q8, A8<br/>Token > 20K<br/>Cascade Delete| State5

    classDef normal fill:#51cf66,stroke:#2b8a3e,color:#fff
    classDef maxed fill:#ffd43b,stroke:#f59f00,color:#000
    classDef deleted fill:#ff6b6b,stroke:#c92a2a,color:#fff

    class State1,State2 normal
    class State3,State4 maxed
    class State5 deleted
```

***

## ğŸ¨ DIAGRAM 6: MEMORY CACHE STRUCTURE

```mermaid
graph TB
    subgraph CacheLayer["Memory Cache - DashMap Thread-Safe"]
        Cache[DashMap Session Storage]
    end

    subgraph Sessions["Active Sessions"]
        S1["Session: 20260125041800123<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>user_id: 123<br/>document_id: 456<br/>created: 04:18:00<br/>expires: 10:18:00<br/>messages: 8<br/>tokens: 18K"]

        S2["Session: 20260125042300456<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>user_id: 456<br/>document_id: 789<br/>created: 04:23:00<br/>expires: 10:23:00<br/>messages: 4<br/>tokens: 8K"]

        S3["Session: 20260125043500789<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>user_id: 789<br/>document_id: NULL<br/>created: 04:35:00<br/>expires: 10:35:00<br/>messages: 2<br/>tokens: 3K"]
    end

    subgraph StateDetail["ConversationState Structure"]
        State["ğŸ“‹ ConversationState<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ session_id: i64<br/>â€¢ user_id: i64<br/>â€¢ document_id: Option i64<br/>â€¢ messages: Vec ChatMessage<br/>â€¢ system_context: String<br/>â€¢ last_retrieval_summary: String<br/>â€¢ last_query_embedding: Vec f32<br/>â€¢ created_at: Instant<br/>â€¢ last_activity: Instant<br/>â€¢ metadata: ConversationMetadata"]
        
        Messages["ğŸ’¬ messages: Vec<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Max 10 items = 5 pairs<br/>[{role: user, content: Q1},<br/> {role: assistant, content: A1},<br/> {role: user, content: Q2},<br/> ...]"]

        Context["ğŸ—ï¸ system_context<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Base Instruction +<br/>Retrieval Summary +<br/>Document Metadata"]

        Embedding["ğŸ¨ last_query_embedding<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Vec f32 [384 dims]<br/>For similarity check"]
    end

    subgraph RAMMonitor["RAM Monitor"]
        Monitor["ğŸ“Š System Info<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Total RAM: 16 GB<br/>Used: 2.4 GB (15%)<br/>Limit: 90%<br/>Status: âœ“ OK"]
    end

    Cache --> S1
    Cache --> S2
    Cache --> S3
    Cache -.->|90% limit check| RAMMonitor

    S1 --> State
    State --> Messages
    State --> Context
    State --> Embedding

    classDef cache fill:#ffd43b,stroke:#f59f00,color:#000
    classDef session fill:#4dabf7,stroke:#1971c2,color:#fff
    classDef structure fill:#9775fa,stroke:#5f3dc4,color:#fff
    classDef monitor fill:#51cf66,stroke:#2b8a3e,color:#fff

    class CacheLayer cache
    class Sessions,S1,S2,S3 session
    class StateDetail,State,Messages,Context,Embedding structure
    class RAMMonitor,Monitor monitor
```

***

## ğŸ¨ DIAGRAM 7: ERROR HANDLING & RETRY FLOW

```mermaid
flowchart TD
    Start([LLM/Retrieval Call]) --> Try1[Attempt 1: Call API]
    
    Try1 --> Check1{Success?}
    
    Check1 -->|YES âœ“| Success[Return Result âœ“]
    Check1 -->|NO âœ—| Log1[Log Error: Attempt 1 failed]
    
    Log1 --> Wait1[Sleep: 1 second]
    Wait1 --> Try2[Attempt 2: Retry Call]
    
    Try2 --> Check2{Success?}
    
    Check2 -->|YES âœ“| Success
    Check2 -->|NO âœ—| Log2[Log Warning: Attempt 2 failed]
    
    Log2 --> Wait2[Sleep: 2 seconds<br/>Exponential backoff]
    Wait2 --> Try3[Attempt 3: Final Retry]
    
    Try3 --> Check3{Success?}
    
    Check3 -->|YES âœ“| Success
    Check3 -->|NO âœ—| MaxRetries[Max Retries Reached: 3]
    
    MaxRetries --> ErrorType{Error Type?}
    
    ErrorType -->|Retrieval| DBError[Return Error:<br/>DB ada gangguan,<br/>harap tunggu atau<br/>tanya Admin IT]
    ErrorType -->|LLM| LLMError[Return Error:<br/>Server ada gangguan,<br/>silakan coba lagi nanti]
    ErrorType -->|Summarization| Fallback[Fallback Strategy:<br/>Return raw chunks<br/>without summary]
    
    Success --> End([Continue Execution])
    DBError --> End
    LLMError --> End
    Fallback --> End

    classDef success fill:#51cf66,stroke:#2b8a3e,color:#fff
    classDef retry fill:#ffd43b,stroke:#f59f00,color:#000
    classDef error fill:#ff6b6b,stroke:#c92a2a,color:#fff

    class Success success
    class Try1,Try2,Try3,Wait1,Wait2,Log1,Log2 retry
    class MaxRetries,DBError,LLMError,Fallback error
```

***

## ğŸ¨ DIAGRAM 8: SESSION LIFECYCLE

```mermaid
stateDiagram-v2
    [*] --> Creating: Client requests<br/>new session_id

    Creating --> Active: Session created<br/>in memory cache<br/>created_at = now()

    Active --> Active: Message exchange<br/>last_activity updated

    Active --> WindowEnforced: >= 5 message pairs<br/>Enforce sliding window

    WindowEnforced --> Active: Continue conversation<br/>with cleaned history

    Active --> TokenOverflow: Total > 20K tokens

    TokenOverflow --> CascadeDeletion: Delete oldest pairs

    CascadeDeletion --> Active: Tokens under limit

    CascadeDeletion --> Truncated: Still > 23K tokens<br/>Force truncate retrieval

    Truncated --> Active: Continue with<br/>truncated context

    Active --> Expired: 6 hours passed<br/>from created_at

    Active --> ServerRestart: Server shutdown

    Expired --> Removed: Lazy deletion<br/>on next access

    ServerRestart --> Removed: All sessions cleared

    Removed --> [*]: Session destroyed

    note right of Active
        Active Session State:
        - messages history
        - system_context
        - last_query_embedding
        - metadata tracking
    end note

    note right of Expired
        Expiration Check:
        created_at + 6h < now()
        Lazy deletion strategy
    end note
```

***

## ğŸ“Š SEMUA DIAGRAM SIAP UNTUK DOKUMENTASI! âœ…

### Summary Diagram yang Dibuat

1. âœ… **High-Level System Architecture** - Component overview
2. âœ… **Detailed Message Flow** - Complete request-response lifecycle (31 steps!)
3. âœ… **Retrieval Decision Tree** - Skip vs Retrieve logic
4. âœ… **Token Management & Cascade Deletion** - Overflow handling
5. âœ… **Sliding Window Visualization** - 5-pair enforcement
6. âœ… **Memory Cache Structure** - DashMap internals
7. âœ… **Error Handling & Retry Flow** - 3x retry with fallback
8. âœ… **Session Lifecycle** - State transitions

***

## ğŸ“ Cara Pakai Diagram di README.md

```markdown
## ğŸ“Š Architecture Diagrams

### System Overview
\`\`\`mermaid
[paste DIAGRAM 1 here]
\`\`\`

### Complete Message Flow
\`\`\`mermaid
[paste DIAGRAM 2 here]
\`\`\`

### Retrieval Decision Logic
\`\`\`mermaid
[paste DIAGRAM 3 here]
\`\`\`

[... and so on]
```

***

## ğŸ¯ Diagram-diagram ini akan sangat membantu untuk

- âœ… **Onboarding** developer baru
- âœ… **Code review** - mudah trace logic flow
- âœ… **Troubleshooting** - identify bottleneck
- âœ… **Documentation** - visual explanation
- âœ… **Presentation** - stakeholder demo

***
