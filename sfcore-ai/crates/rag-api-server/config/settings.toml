[server]
host = "0.0.0.0"
port = 3000
max_connections = 1000

[security]
allowed_ips = ["127.0.0.1", "::1"]

[security.custom_headers]
app_id = "X-App-ID"
api_key = "X-Api-Key"
request_signature = "X-Request-Signature"
timestamp_tolerance = 300

[database]
url = "postgres://postgres:postgres@localhost:5432/rag_db"
pool_max_size = 20
pool_timeout_seconds = 30

[embedding]
model = "text-embedding-3-small"
base_url = "https://api.openai.com/v1"
dimension = 1536

[llm]
base_url = "https://api.openai.com/v1"
timeout_seconds = 300
max_tokens = 2000
stream_response = true

[rag]
retrieval_top_k = 5
chunk_size = 512
chunk_overlap_percentage = 0.1
rerank_enabled = false
max_context_length = 8192
max_context_tokens = 20000
document_path = "/home/sfcore/sfcore-dms-docs"

[prompts]
main_system_prompt = "You are a helpful assistant."
context_extraction_system_prompt = "Context: {{CHUNKS}}"

[limits]
embedding_concurrency = 8
db_search_concurrency = 20
llm_generate_concurrency = 4
llm_stream_concurrency = 2
acquire_timeout_ms = 15000