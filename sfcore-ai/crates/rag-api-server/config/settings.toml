[server]
host = "0.0.0.0"
port = 8000
max_connections = 1000

[security]
allowed_ips = [
    "0.0.0.0/0",
    "::/0",
    "127.0.0.1"
]

[security.custom_headers]
app_id = "DMS-CLIENT-APP-2026"
api_key = "SHUBA-APP-DMS-RAG"
request_signature = "enabled"
timestamp_tolerance = 3153600

[database]
url = "postgresql://postgres:P%40ssw0rd@localhost:6432/dms_demo?sslmode=disable"
pool_max_size = 20
pool_timeout_seconds = 30

# ==========================================
# KONFIGURASI GEMINI (BARU!)
# ==========================================
# Isi API KEY di sini untuk mengaktifkan Gemini secara global.
# Jika ini diisi, settingan [embedding] dan [llm] di bawah akan DI-OVERRIDE otomatis.
[gemini]
enabled = false
api_key = "[ENCRYPTION_KEY]"
model = "models/gemini-2.5-flash-lite-preview-09-2025"
embedding_model = "text-embedding-004"
base_url = "https://generativelanguage.googleapis.com/v1beta/openai"

#*List Of Model Gemini *#
# models/gemini-2.5-pro - models/gemini-2.5-flash 
# models/gemini-2.5-flash-lite - models/gemini-pro-latest
# models/gemini-flash-lite-latest - models/gemini-flash-latest - models/gemma-3-27b-it
# models/gemini-2.0-flash-lite - models/gemini-2.0-flash-lite-001  - models/gemini-2.0-flash

# ==========================================
# KONFIGURASI STANDAR (LEGACY / LOCAL)
# ==========================================
[embedding]
model = "Qwen3-embedding-0.6B"
base_url = "http://127.0.0.1:8081"
dimension = 1024 # Note: Jika Gemini aktif, ini akan otomatis jadi 768

[llm]
base_url = "http://127.0.0.1:8080"
timeout_seconds = 60
max_tokens = 32000
stream_response = true

[rag]
retrieval_top_k = 5
chunk_size = 1200
chunk_overlap_percentage = 0.1
rerank_enabled = false

# Gemini set 1000000, Lokal set = 12000
max_context_length = 12000
max_context_tokens = 12000

# Gemini set 64000, Lokal set = 4000
deep_scan_batch_tokens = 4000
document_path = "C:/DMS/uploads/"


[limits]
embedding_concurrency = 5
db_search_concurrency = 20
llm_generate_concurrency = 5
llm_stream_concurrency = 5
acquire_timeout_ms = 60000
embedding_batch_size = 10

[prompts]

[prompts.local]
main_system_prompt = """
Anda adalah asisten AI cerdas untuk Sistem Manajemen Dokumen.
Waktu Server: {{CURRENT_DATETIME}}
Dokumen Aktif:
{{DOC_LIST}}

Instruksi:
- Jawab pertanyaan berdasarkan konteks dokumen.
- Gunakan Bahasa Indonesia yang natural dan jelas.
- Jika tidak ada info di dokumen, katakan jujur.

Referensi:
- [Judul Dokumen]
"""

context_extraction_system_prompt = """
Konteks Dokumen:
{{CHUNKS}}
"""

rag_query_system_prompt = """
Anda adalah asisten AI RAG. Jawab berdasarkan konteks berikut:
{{CONTEXT}}
"""

deep_scan_system_prompt = """
User Query: "{{QUERY}}"
Pilih chunk ID yang relevan dari daftar di bawah.
Output JSON: {"relevant_chunk_ids": [1, 2, ...]}
"""

[prompts.gemini]
main_system_prompt = """
Anda adalah asisten AI cerdas untuk Sistem Manajemen Dokumen.
Waktu Server: {{CURRENT_DATETIME}}
Dokumen Aktif:
{{DOC_LIST}}

Instruksi:
- Jawab pertanyaan berdasarkan konteks dokumen.
- Gunakan Bahasa Indonesia yang natural dan jelas.
- Jika tidak ada info di dokumen, katakan jujur.

Referensi:
- [Judul Dokumen]
"""

context_extraction_system_prompt = """
Konteks Dokumen:
{{CHUNKS}}
"""

rag_query_system_prompt = """
Anda adalah asisten AI RAG. Jawab berdasarkan konteks berikut:
{{CONTEXT}}
"""

deep_scan_system_prompt = """
User Query: "{{QUERY}}"
Pilih chunk ID yang relevan dari daftar di bawah.
Output JSON: {"relevant_chunk_ids": [1, 2, ...]}
"""
