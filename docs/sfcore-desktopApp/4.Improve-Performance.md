## IMPROVEMENT PERFORMANCE

Aplikasi Anda mengalami delay karena setiap token individual dari AI inference langsung trigger UI repaint, tanpa batching. Proses streaming melewati beberapa layer yang tidak efisien: [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/116629904/4d1ef7e0-2c9f-4a75-a6cc-e78e0465f22e/engine_vm.rs)

- `UdsClient.stream_chat()` mengirim setiap token via channel
- Setiap token trigger `AppEvent::EngineResponse`
- `append_response()` modifikasi string dan trigger full UI repaint
- UI re-render seluruh message list di `panel_view.rs` [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/116629904/aec2bd2d-95ec-4282-a3a8-9998dbb12c40/panel_view.rs)

## Rekomendasi Improvement Performance

### 1. Token Batching di Layer Streaming

Modifikasi `engine_vm.rs` untuk batch tokens sebelum kirim ke UI:

```rust
pub fn send_message(&mut self) {
    // ... existing code ...
    
    tokio::spawn(async move {
        let client = UdsClient::new(&socket_path);
        let (tx_stream, mut rx_stream) = mpsc::unbounded_channel();
        
        let tx_event_stream = tx_event.clone();
        let stream_handle = tokio::spawn(async move {
            client.stream_chat(&prompt, 1024, tx_stream).await
        });
        
        // IMPROVEMENT: Batch tokens dengan buffer + timer
        let mut buffer = String::with_capacity(256);
        let mut last_update = Instant::now();
        let batch_interval = Duration::from_millis(50); // 20 updates/sec max
        
        while let Some(chunk) = rx_stream.recv().await {
            buffer.push_str(&chunk);
            
            // Kirim batch jika:
            // 1. Buffer cukup besar (>= 10 chars), ATAU
            // 2. Sudah lewat interval waktu
            if buffer.len() >= 10 || last_update.elapsed() >= batch_interval {
                if !buffer.is_empty() {
                    let _ = tx_event_stream.send(AppEvent::EngineResponse(buffer.clone()));
                    buffer.clear();
                    last_update = Instant::now();
                }
            }
        }
        
        // Kirim sisa buffer
        if !buffer.is_empty() {
            let _ = tx_event_stream.send(AppEvent::EngineResponse(buffer));
        }
        
        // ... existing cleanup code ...
    });
}
```

### 2. Controlled Repaint dengan Rate Limiting

Di `panel_view.rs`, tambahkan kontrol untuk rate limiting repaint: [an4t](https://an4t.com/rust-gui-chat-client-rust/)

```rust
fn render_engine(
    ui: &mut egui::Ui,
    ctx: &egui::Context,
    vm: &mut EngineViewModel,
    textures: &mut TextureCache,
) {
    // ... existing log panel code ...
    
    // IMPROVEMENT: Request repaint hanya jika sedang streaming
    if vm.is_loading {
        // Limit repaint ke 60fps saat streaming
        ctx.request_repaint_after(Duration::from_millis(16));
    }
    
    // ... rest of render code ...
}
```

### 3. Optimasi Message Rendering dengan Lazy Loading

Limit jumlah message yang di-render untuk improve scrolling performance: [github](https://github.com/emilk/egui/issues/3086)

```rust
// Di panel_view.rs dalam render_engine()
ScrollArea::vertical()
    .max_height(response_height)
    .min_scrolled_height(response_height)
    .stick_to_bottom(true)
    .auto_shrink([false, false]) // IMPROVEMENT: Prevent auto-shrink
    .show(ui, |ui| {
        ui.set_min_width(ui.available_width());
        ui.set_min_height(response_height);
        
        if vm.messages.is_empty() {
            // ... empty state ...
        } else {
            // IMPROVEMENT: Hanya render message yang visible
            let visible_start = vm.messages.len().saturating_sub(50);
            
            if visible_start > 0 {
                ui.label(
                    RichText::new(format!("... {} pesan sebelumnya", visible_start))
                        .size(10.0)
                        .color(Color32::DARK_GRAY)
                );
            }
            
            for msg in &vm.messages[visible_start..] {
                // ... existing render code ...
            }
        }
    });
```

### 4. Gunakan `Arc<String>` untuk Avoid Cloning

Di `engine_vm.rs`, ubah `ChatMessage` untuk reduce memory allocation: [stackoverflow](https://stackoverflow.com/questions/73770247/why-is-the-performance-of-rust-tokio-so-poor-release-test-result-updated)

```rust
use std::sync::Arc;

#[derive(Debug, Clone)]
pub struct ChatMessage {
    pub role: MessageRole,
    pub content: Arc<String>, // IMPROVEMENT: Gunakan Arc
}

// Update append_response()
pub fn append_response(&mut self, text: &str) {
    // ... existing validation code ...
    
    if self.is_loading {
        let last_is_assistant = self.messages
            .last()
            .map_or(false, |m| matches!(m.role, MessageRole::Assistant));
        
        if !last_is_assistant {
            self.messages.push(ChatMessage {
                role: MessageRole::Assistant,
                content: Arc::new(String::new()),
            });
        }
        
        // IMPROVEMENT: Update via Arc::make_mut untuk efisiensi
        if let Some(last_msg) = self.messages.last_mut() {
            if matches!(last_msg.role, MessageRole::Assistant) {
                let content_mut = Arc::make_mut(&mut last_msg.content);
                content_mut.push_str(text);
                // ... metrics update ...
            }
        }
    }
}
```

### 5. Debounce UI Updates di Main Loop

Tambahkan debouncing di event handler untuk prevent excessive repaints:

```rust
// Di main app loop atau AppEvent handler
use std::collections::VecDeque;

struct AppState {
    pending_responses: VecDeque<String>,
    last_ui_update: Instant,
    // ... existing fields ...
}

// Handle events dengan batching
fn handle_events(&mut self, ctx: &egui::Context) {
    while let Ok(event) = self.event_rx.try_recv() {
        match event {
            AppEvent::EngineResponse(text) => {
                self.pending_responses.push_back(text);
            }
            // ... other events ...
        }
    }
    
    // Process batched responses setiap 50ms
    if self.last_ui_update.elapsed() > Duration::from_millis(50) {
        while let Some(text) = self.pending_responses.pop_front() {
            self.engine_vm.append_response(&text);
        }
        self.last_ui_update = Instant::now();
        ctx.request_repaint();
    }
}
```

### 6. Compile dengan Optimization Flags

Pastikan `Cargo.toml` menggunakan profile optimized: [stackoverflow](https://stackoverflow.com/questions/73770247/why-is-the-performance-of-rust-tokio-so-poor-release-test-result-updated)

```toml
[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true
```

## Performance Metrics Yang Diharapkan

Setelah implementasi improvements di atas, Anda seharusnya mendapatkan: [an4t](https://an4t.com/rust-gui-chat-client-rust/)

- **Latency**: Reduce dari per-token (1-5ms) ke batch update (50ms)
- **Throughput**: 20 UI updates/second max vs 100-1000+ per second sebelumnya  
- **CPU Usage**: Turun 60-80% karena reduced repaint calls
- **Smooth Streaming**: Token muncul dalam chunks, terasa lebih natural

Implementasi bertahap mulai dari #1 (token batching) akan memberikan impact terbesar pada performa aplikasi Anda. [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/116629904/972eb1c2-57e1-4dee-9d45-e8396b9b104d/uds_client.rs)
